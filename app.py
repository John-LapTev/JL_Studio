"""
JL Studio - –°–∏—Å—Ç–µ–º–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
–í–µ—Ä—Å–∏—è: 1.0
–ê–≤—Ç–æ—Ä: John LapTev
Copyright (c) 2024 John LapTev. –í—Å–µ –ø—Ä–∞–≤–∞ –∑–∞—â–∏—â–µ–Ω—ã.
"""

import os
import json
import logging
import torch
import pandas as pd
from PIL import Image
from pathlib import Path
from huggingface_hub import HfApi
from datetime import datetime
import time
from diffusers import FluxPipeline, AutoencoderTiny, AutoencoderKL, AutoPipelineForImage2Image
from live_preview_helpers import JL_calculate_shift, JL_retrieve_timesteps, JL_flux_pipe_call_that_returns_an_iterable_of_images
import random
import numpy as np
import sys

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã
JL_MAX_SEED = 2**32-1
JL_DEFAULT_QUALITY = 100
JL_DEFAULT_FORMAT = "PNG"
JL_DEFAULT_NAME_FORMAT = "prompt"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã–≤–æ–¥–∞
print("\n" + "="*80)
print("üöÄ –ó–ê–ü–£–°–ö JL STUDIO")
print("="*80 + "\n")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
print("üîç –ü–†–û–í–ï–†–ö–ê –û–ö–†–£–ñ–ï–ù–ò–Ø")
print("‚îú‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞...", end=" ")
token_path = Path('token.txt')
if token_path.exists():
    with open(token_path) as f:
        token = f.read().strip()
        os.environ["HUGGING_FACE_HUB_TOKEN"] = token
    print("‚úÖ")
else:
    print("‚ùå\n‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª token.txt –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    sys.exit(1)

print("‚îú‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU...", end=" ")
if torch.cuda.is_available():
    gpu_name = torch.cuda.get_device_name(0)
    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
    print("‚úÖ")
    print(f"   ‚îú‚îÄ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {gpu_name}")
    print(f"   ‚îî‚îÄ –ü–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
else:
    print("‚ö†Ô∏è GPU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è CPU")

print("‚îî‚îÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞–º—è—Ç–∏...", end=" ")
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.backends.cudnn.benchmark = True
print("‚úÖ")

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
jl_dtype = torch.float16
jl_model_path = Path("models/flux")

print("\nüì¶ –ü–†–û–í–ï–†–ö–ê –§–ê–ô–õ–û–í")
print(f"‚îú‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–ø–∫–∏ –º–æ–¥–µ–ª–µ–π...", end=" ")
if not jl_model_path.exists():
    print("‚ùå\n‚ùå –û–®–ò–ë–ö–ê: –ü–∞–ø–∫–∞ models/flux –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
    sys.exit(1)
print("‚úÖ")

print("‚îú‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ model_index.json...", end=" ")
model_index = jl_model_path / "model_index.json"
if not model_index.exists():
    print("‚ùå\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω model_index.json!")
    sys.exit(1)
with open(model_index) as f:
    config = json.load(f)
print("‚úÖ")

print("‚îî‚îÄ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏...", end=" ")
model_file = jl_model_path / "transformer" / "flux1-dev.sft"
if not model_file.exists():
    print("‚ùå\n‚ùå –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏!")
    sys.exit(1)
print("‚úÖ")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
print("\n‚öôÔ∏è –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô")

try:
    print("‚îú‚îÄ –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω...", end=" ")
    jl_pipe = FluxPipeline.from_pretrained(
        "models/flux",
        torch_dtype=jl_dtype,
        device_map=None,
        use_safetensors=True,
        local_files_only=True,
        low_cpu_mem_usage=True,
        max_sequence_length=512
    )
    print("‚úÖ")
    
    print("‚îú‚îÄ VAE tiny...", end=" ")
    jl_taef1 = AutoencoderTiny.from_pretrained(
        "madebyollin/taef1",
        torch_dtype=jl_dtype,
        low_cpu_mem_usage=True
    )
    print("‚úÖ")
    
    print("‚îú‚îÄ –û—Å–Ω–æ–≤–Ω–æ–π VAE...", end=" ")
    jl_good_vae = AutoencoderKL.from_pretrained(
        "black-forest-labs/FLUX.1-dev",
        subfolder="vae",
        torch_dtype=jl_dtype
    ).to("cuda" if torch.cuda.is_available() else "cpu")
    print("‚úÖ")

    print("‚îú‚îÄ Image-to-image –ø–∞–π–ø–ª–∞–π–Ω...", end=" ")
    jl_pipe_i2i = AutoPipelineForImage2Image.from_pretrained(
        "black-forest-labs/FLUX.1-dev",
        vae=jl_good_vae,
        transformer=jl_pipe.transformer,
        text_encoder=jl_pipe.text_encoder,
        tokenizer=jl_pipe.tokenizer,
        text_encoder_2=jl_pipe.text_encoder_2,
        tokenizer_2=jl_pipe.tokenizer_2,
        torch_dtype=jl_dtype
    )
    print("‚úÖ")
    
    print("‚îú‚îÄ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞...", end=" ")
    jl_pipe.vae_preview = jl_taef1 # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±—ã—Å—Ç—Ä—ã–π VAE –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞
    jl_pipe.vae = jl_good_vae      # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π VAE –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    print("‚úÖ")
    
    print("‚îî‚îÄ CPU offloading...", end=" ")
    jl_device = "cuda" if torch.cuda.is_available() else "cpu"
    jl_pipe.enable_sequential_cpu_offload(device=jl_device)
    jl_pipe_i2i.enable_sequential_cpu_offload(device=jl_device)
    jl_pipe.flux_pipe_call_that_returns_an_iterable_of_images = JL_flux_pipe_call_that_returns_an_iterable_of_images.__get__(jl_pipe)
    print("‚úÖ")

except Exception as e:
    print(f"\n‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –º–æ–¥–µ–ª–µ–π: {str(e)}")
    raise

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π
print("\nüì• –ó–ê–ì–†–£–ó–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ LoRA
print("‚îú‚îÄ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ø–∏—Å–∫–∞ LoRA...", end=" ")
try:
    with open('loras.json', 'r', encoding='utf-8') as f:
        jl_loras = json.load(f)
    print(f"‚úÖ (–Ω–∞–π–¥–µ–Ω–æ: {len(jl_loras)})")
except Exception as e:
    print(f"‚ö†Ô∏è {str(e)}")
    jl_loras = []

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤
print("‚îî‚îÄ –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤...", end=" ")
try:
    jl_prompts_df = pd.read_csv('prompts.csv', header=None, encoding='utf-8')
    jl_prompt_values = jl_prompts_df[0].values
    print(f"‚úÖ (–Ω–∞–π–¥–µ–Ω–æ: {len(jl_prompt_values)})")
except Exception as e:
    print(f"‚ö†Ô∏è {str(e)}")
    jl_prompt_values = []

def JL_load_local_loras():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –ª–æ–∫–∞–ª—å–Ω—ã—Ö LoRA –∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –ø–∞–ø–∫–∏"""
    loras_path = Path("models/flux/loras")
    loras_path.mkdir(exist_ok=True)
    local_loras = []

    print("\nüìÅ –î–û–°–¢–£–ü–ù–´–ï –õ–û–ö–ê–õ–¨–ù–´–ï LORA:")
    
    for lora_file in loras_path.rglob("*.safetensors"):
        rel_path = lora_file.relative_to(loras_path)
        folder_path = str(rel_path.parent) if rel_path.parent != Path(".") else ""
        display_name = str(rel_path.with_suffix(""))
        display_name = display_name.replace("\\", "/")

        # –ü–æ–∏—Å–∫ –ø—Ä–µ–≤—å—é –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π LoRA
        preview = None
        preview_extensions = ['.png', '.jpg', '.jpeg', '.webp']
        for ext in preview_extensions:
            preview_path = lora_file.with_suffix(ext)
            if preview_path.exists():
                preview = str(preview_path)
                break
        
        local_loras.append({
            "title": display_name,
            "path": str(lora_file),
            "folder": folder_path,
            "trigger_word": "",
            "preview": preview
        })
        
        if folder_path:
            print(f"‚îú‚îÄ [{folder_path}] {display_name}")
        else:
            print(f"‚îú‚îÄ {display_name}")
    
    local_loras.sort(key=lambda x: (x["folder"], x["title"]))
    if local_loras:
        print(f"‚îî‚îÄ –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ: {len(local_loras)}")
    else:
        print("‚îî‚îÄ –õ–æ–∫–∞–ª—å–Ω—ã–µ LoRA –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    return local_loras

def JL_find_best_lora_file(repo_id):
    """–ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–∞–π–ª LoRA"""
    try:
        from huggingface_hub import list_repo_files
        
        files = list_repo_files(repo_id)
        safetensors_files = [f for f in files if f.endswith('.safetensors')]
        
        if not safetensors_files:
            print(f"‚ö†Ô∏è LoRA —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ {repo_id}")
            return None
            
        if len(safetensors_files) == 1:
            return safetensors_files[0]
            
        repo_name = repo_id.split('/')[-1].lower()
        
        priority_names = [
            f"{repo_name}.safetensors",
            "lora.safetensors",
            "model.safetensors",
            "flux.safetensors"
        ]
        
        for name in priority_names:
            if name in safetensors_files:
                print(f"‚úì –ù–∞–π–¥–µ–Ω –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π —Ñ–∞–π–ª: {name}")
                return name
                
        for file in safetensors_files:
            if repo_name in file.lower():
                print(f"‚úì –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –ø–æ –∏–º–µ–Ω–∏ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {file}")
                return file
                
        print(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {safetensors_files[0]}")
        return safetensors_files[0]
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ñ–∞–π–ª–∞ LoRA: {e}")
        return None

def JL_load_image(image_path):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    try:
        image = Image.open(image_path)
        if image.mode not in ("RGB", "RGBA"):
            image = image.convert("RGB")
        return image
    except Exception as e:
        raise ValueError(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")

def JL_save_generated_image(image, prompt, seed, format='PNG', quality=100, name_format='prompt'):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%d.%m.%Y_%H%M%S")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –ø—Ä–æ–º–ø—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞ –∏–º–µ–Ω–∏
    if name_format == 'full':
        prompt_slug = sanitize_filename(prompt[:15])
    else:  # prompt
        prompt_slug = sanitize_filename(prompt[:30])
    
    if name_format == 'full':
        filename = f"{timestamp}_{seed}_{prompt_slug}"
    elif name_format == 'date':
        filename = timestamp
    elif name_format == 'seed':
        filename = f"{timestamp}_{seed}"
    else:  # prompt
        filename = prompt_slug
        
    base_filename = filename
    counter = 0
    while True:
        suffix = f"({counter})" if counter > 0 else ""
        filename_with_suffix = f"{base_filename}{suffix}"
        full_path = output_dir / f"{filename_with_suffix}.{format.lower()}"
        if not full_path.exists():
            break
        counter += 1
    
    try:
        if format.upper() in ['JPEG', 'JPG']:
            image.save(full_path, format=format.upper(), quality=quality, optimize=True)
        elif format.upper() == 'WEBP':
            image.save(full_path, format='WEBP', quality=quality, method=6)
        else:  # PNG
            image.save(full_path, format='PNG', optimize=True)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'prompt': prompt,
            'seed': seed,
            'timestamp': str(datetime.now()),
            'format': format,
            'quality': quality
        }
        
        metadata_path = full_path.with_suffix('.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {full_path}")
        return str(full_path)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
        raise ValueError(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}")

def JL_randomize_prompt():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞"""
    if jl_prompt_values is not None and len(jl_prompt_values) > 0:
        return random.choice(jl_prompt_values.tolist())
    return ""

def JL_generate_image(prompt_mash, steps, seed, cfg_scale, width, height, lora_scale):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Args:
        prompt_mash (str): –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å trigger words
        steps (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        seed (int): –°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        cfg_scale (float): –ü–∞—Ä–∞–º–µ—Ç—Ä CFG
        width (int): –®–∏—Ä–∏–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        height (int): –í—ã—Å–æ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        lora_scale (float): –°–∏–ª–∞ –≤–ª–∏—è–Ω–∏—è LoRA
    """
    generator = torch.Generator(device="cuda").manual_seed(seed)
    start_time = time.time()
    total_time = 0
    
    with torch.inference_mode():
        for i, img in enumerate(jl_pipe.flux_pipe_call_that_returns_an_iterable_of_images(
            prompt=prompt_mash,
            num_inference_steps=steps,
            guidance_scale=cfg_scale,
            width=width,
            height=height,
            generator=generator,
            joint_attention_kwargs={"scale": lora_scale},
            output_type="pil",
            good_vae=jl_good_vae
        )):
            current_step = i + 1
            elapsed_time = time.time() - start_time
            eta = (elapsed_time / current_step) * (steps - current_step) if current_step > 0 else 0
            
            # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å—Ç—Ä–æ–∫—É –∏ –≤—ã–≤–æ–¥–∏–º –Ω–æ–≤—É—é
            sys.stdout.write('\r')
            sys.stdout.write(f"[{'=' * (current_step * 50 // steps)}{' ' * (50 - current_step * 50 // steps)}] ")
            sys.stdout.write(f"{current_step}/{steps} —à–∞–≥ ")
            sys.stdout.write(f"({(current_step/steps)*100:.1f}%) ")
            sys.stdout.write(f"[{int(elapsed_time)}—Å/{int(eta)}—Å] ")
            sys.stdout.flush()
            
            if i == steps - 1:  # –ü–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–≥
                total_time = time.time() - start_time
                sys.stdout.write('\n\n')  # –ü–µ—Ä–µ–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                print(f"‚ú® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f} —Å–µ–∫—É–Ω–¥\n")
            
            yield img

def JL_generate_image_to_image(prompt_mash, image_input_path, image_strength, steps, cfg_scale, width, height, lora_scale, seed):
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥—Ä—É–≥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Args:
        prompt_mash (str): –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        image_input_path (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        image_strength (float): –°–∏–ª–∞ –≤–ª–∏—è–Ω–∏—è –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        steps (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤
        cfg_scale (float): –ü–∞—Ä–∞–º–µ—Ç—Ä CFG
        width (int): –®–∏—Ä–∏–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        height (int): –í—ã—Å–æ—Ç–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        lora_scale (float): –°–∏–ª–∞ –≤–ª–∏—è–Ω–∏—è LoRA
        seed (int): –°–∏–¥ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    """
    start_time = time.time()
    
    try:
        image_input = JL_load_image(image_input_path)
        print(f"üì• –ó–∞–≥—Ä—É–∂–µ–Ω–æ –∏—Å—Ö–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {image_input.size}")
        
        generator = torch.Generator(device="cuda").manual_seed(seed)
        final_image = jl_pipe_i2i(
            prompt=prompt_mash,
            image=image_input,
            strength=image_strength,
            num_inference_steps=steps,
            guidance_scale=cfg_scale,
            width=width,
            height=height,
            generator=generator,
            joint_attention_kwargs={"scale": lora_scale},
            output_type="pil"
        ).images[0]
        
        total_time = time.time() - start_time
        print(f"\n‚ú® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f} —Å–µ–∫—É–Ω–¥\n")
        return final_image
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ img2img: {str(e)}")
        raise

def sanitize_filename(prompt: str, max_length: int = 30) -> str:
    """–û—á–∏—Å—Ç–∫–∞ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
    # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã
    invalid_chars = '<>:"/\\|?*'
    filename = prompt
    for char in invalid_chars:
        filename = filename.replace(char, '_')
    
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    filename = " ".join(filename.split())[:max_length]
    return filename.strip()

print("\n‚úÖ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
print("="*80)